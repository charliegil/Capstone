{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1> Title <h1>",
   "id": "11a96e8bb44d5201"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3> Step 1 - Setup </h3>\n",
    "\n",
    "imports, declaring directories, and utility functions:\n",
    "\n",
    "load_data(filepath, fraction)\n",
    "- Reads a dataset from a file.\n",
    "- Extracts only a specified fraction of the data.\n",
    "- Returns the extracted portion as a NumPy array.\n",
    "\n",
    "plot_two_lines()\n",
    "- Plots two lines on the same graph using Plotly.\n",
    "- Assigns different colors to each line (blue and red).\n",
    "- Adds labels for the axes and a title.\n",
    "- Enables interactive features like hovering over points.\n",
    "- Displays the plot in a window."
   ],
   "id": "f015870d951abe9f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-24T07:36:22.864497Z",
     "start_time": "2025-03-24T07:36:22.551910Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import optuna\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import os\n",
    "\n",
    "directory = r\"C:\\Users\\alexa\\PycharmProjects\\CapstoneProject\\.venv\"\n",
    "data_dir = os.path.join(directory, 'data', 'Constellation', '')\n",
    "results_dir = os.path.join(directory, 'model results', 'Constellation')\n",
    "\n",
    "def load_data(filepath, fraction):\n",
    "    # Load the entire dataset\n",
    "    full_data = pd.read_csv(filepath, sep=r',', header=None).to_numpy()\n",
    "\n",
    "    # Calculate the number of rows to load\n",
    "    num_rows = int(len(full_data) * fraction)\n",
    "\n",
    "    # Select the first `num_rows` rows (contiguous block)\n",
    "    sampled_data = full_data[:num_rows]\n",
    "\n",
    "    return sampled_data\n",
    "\n",
    "def plot_two_lines(x1, y1, x2, y2, title, x_label, y_label, label1=\"Line 1\", label2=\"Line 2\"):\n",
    "    \"\"\"\n",
    "    Creates an interactive Plotly plot for two solid lines over the same x-axis.\n",
    "\n",
    "    Parameters:\n",
    "    - x1, y1: Data for the first line\n",
    "    - x2, y2: Data for the second line\n",
    "    - title: Plot title\n",
    "    - x_label: Label for the x-axis\n",
    "    - y_label: Label for the y-axis\n",
    "    - label1: Legend name for the first line (default: \"Line 1\")\n",
    "    - label2: Legend name for the second line (default: \"Line 2\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an interactive figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add first line trace (solid blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x1, y=y1,\n",
    "        mode='lines', name=label1,\n",
    "        line=dict(color='blue', width=2)  # Solid line, blue color\n",
    "    ))\n",
    "\n",
    "    # Add second line trace (solid red)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x2, y=y2,\n",
    "        mode='lines', name=label2,\n",
    "        line=dict(color='red', width=2)  # Solid line, red color\n",
    "    ))\n",
    "\n",
    "    # Configure layout for better visibility\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=x_label,\n",
    "        yaxis_title=y_label,\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"x\",  # Enables hover tool on x-axis\n",
    "    )\n",
    "\n",
    "    # Show the interactive plot\n",
    "    fig.show()"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01moptim\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\CapstoneProject\\.venv3\\Lib\\site-packages\\torch\\__init__.py:2475\u001B[0m\n\u001B[0;32m   2471\u001B[0m     torch_module_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;18m__name__\u001B[39m, device_type])\n\u001B[0;32m   2472\u001B[0m     sys\u001B[38;5;241m.\u001B[39mmodules[torch_module_name] \u001B[38;5;241m=\u001B[39m module\n\u001B[1;32m-> 2475\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m   2476\u001B[0m     export \u001B[38;5;28;01mas\u001B[39;00m export,\n\u001B[0;32m   2477\u001B[0m     func \u001B[38;5;28;01mas\u001B[39;00m func,\n\u001B[0;32m   2478\u001B[0m     library \u001B[38;5;28;01mas\u001B[39;00m library,\n\u001B[0;32m   2479\u001B[0m     return_types \u001B[38;5;28;01mas\u001B[39;00m return_types,\n\u001B[0;32m   2480\u001B[0m )\n\u001B[0;32m   2481\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m cond \u001B[38;5;28;01mas\u001B[39;00m cond, while_loop \u001B[38;5;28;01mas\u001B[39;00m while_loop\n\u001B[0;32m   2482\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m vmap \u001B[38;5;28;01mas\u001B[39;00m vmap\n",
      "File \u001B[1;32m~\\PycharmProjects\\CapstoneProject\\.venv3\\Lib\\site-packages\\torch\\export\\__init__.py:64\u001B[0m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msymbolic_shapes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m StrictMinMaxConstraint\n\u001B[0;32m     44\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConstraint\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDim\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnflattenedModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     61\u001B[0m ]\n\u001B[1;32m---> 64\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdynamic_shapes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Constraint, Dim, dims, ShapesCollection\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexported_program\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram, ModuleCallEntry, ModuleCallSignature\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph_signature\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExportBackwardSignature, ExportGraphSignature\n",
      "File \u001B[1;32m~\\PycharmProjects\\CapstoneProject\\.venv3\\Lib\\site-packages\\torch\\export\\dynamic_shapes.py:23\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     _get_node_type,\n\u001B[0;32m     13\u001B[0m     BUILTIN_TYPES,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     tree_map_with_path,\n\u001B[0;32m     21\u001B[0m )\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexported_program\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Symbol\n",
      "File \u001B[1;32m~\\PycharmProjects\\CapstoneProject\\.venv3\\Lib\\site-packages\\torch\\export\\exported_program.py:26\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcontextlib\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m contextmanager\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     13\u001B[0m     Any,\n\u001B[0;32m     14\u001B[0m     Callable,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m     Union,\n\u001B[0;32m     24\u001B[0m )\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m autograd_not_implemented\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_library\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfake_class_registry\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FakeScriptObject\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m first_call_function_nn_module_stack\n",
      "File \u001B[1;32m~\\PycharmProjects\\CapstoneProject\\.venv3\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcond\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m cond\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflex_attention\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      3\u001B[0m     flex_attention,\n\u001B[0;32m      4\u001B[0m     flex_attention_backward,\n\u001B[0;32m      5\u001B[0m )\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhints_wrap\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m hints_wrapper\n",
      "File \u001B[1;32m~\\PycharmProjects\\CapstoneProject\\.venv3\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_subclasses\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional_tensor\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpytree\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DispatchKey\n",
      "File \u001B[1;32m~\\PycharmProjects\\CapstoneProject\\.venv3\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Any, Callable, ContextManager, Dict, List, Optional, Tuple, Union\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01minductor_config\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpytree\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _functionalization_reapply_views_tls \u001B[38;5;28;01mas\u001B[39;00m _reapply_views\n",
      "File \u001B[1;32m~\\PycharmProjects\\CapstoneProject\\.venv3\\Lib\\site-packages\\torch\\_inductor\\config.py:44\u001B[0m\n\u001B[0;32m     40\u001B[0m verbose_progress \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# use fx aot graph codegen cache\u001B[39;00m\n\u001B[0;32m     43\u001B[0m fx_graph_cache \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m---> 44\u001B[0m     os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTORCHINDUCTOR_FX_GRAPH_CACHE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_fbcode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     45\u001B[0m )\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# use remote fx aot graph codegen cache\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# False: Disables the cache\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# True: Enables the cache\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# None: Not set -- Off for OSS, JustKnobs based for internal\u001B[39;00m\n\u001B[0;32m     51\u001B[0m fx_graph_remote_cache: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m fx_graph_remote_cache_default()\n",
      "File \u001B[1;32m~\\PycharmProjects\\CapstoneProject\\.venv3\\Lib\\site-packages\\torch\\_inductor\\config.py:9\u001B[0m, in \u001B[0;36mis_fbcode\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mis_fbcode\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m----> 9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mversion\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgit_version\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step 2",
   "id": "ee3bcf54436069ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_data = load_data(os.path.join(data_dir, '256QAM_input_complex.csv'), 1)\n",
    "output_data = load_data(os.path.join(data_dir, '256QAM_output_complex.csv'), 1)\n",
    "\n",
    "\n",
    "class ModelDataset(Dataset):\n",
    "    def __init__(self, data, window_size, step_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - data (numpy array): 2D array of shape (N, 5) with columns [Time, I_in, Q_in, I_out, Q_out]\n",
    "        - window_size (int): Number of time steps in each window\n",
    "        - step_size (int): Step size between windows\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.num_windows = (len(self.data) - self.window_size) // self.step_size + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_windows\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single window of data.\n",
    "\n",
    "        - X (torch.Tensor): Full input sequence (window_size,)\n",
    "        - y (torch.Tensor): Target (middle value of output signal)\n",
    "        - t (float): Time index of the middle point\n",
    "        \"\"\"\n",
    "        start_idx = idx * self.step_size\n",
    "        end_idx = start_idx + self.window_size\n",
    "        window = self.data[start_idx:end_idx]\n",
    "\n",
    "        # Extract input, output, and time signals\n",
    "        time_signal = window[:, 0]  # Extract time column\n",
    "        input_I = window[:, 1]\n",
    "        input_Q = window[:, 2]\n",
    "        output_I = window[:, 3]\n",
    "        output_Q = window[:, 4]\n",
    "\n",
    "        # Find middle index\n",
    "        middle_index = len(output_I) // 2\n",
    "        middle_time = time_signal[middle_index]  # Time at middle of the window\n",
    "\n",
    "        # Normalize each window independently\n",
    "        input_I_mean, input_I_std = input_I.mean(), input_I.std()\n",
    "        input_Q_mean, input_Q_std = input_Q.mean(), input_Q.std()\n",
    "        output_I_mean, output_I_std = output_I.mean(), output_I.std()\n",
    "        output_Q_mean, output_Q_std = output_Q.mean(), output_Q.std()\n",
    "\n",
    "        if input_I_std != 0:\n",
    "            input_I = (input_I - input_I_mean) / input_I_std\n",
    "        if input_Q_std != 0:\n",
    "            input_Q = (input_Q - input_Q_mean) / input_Q_std\n",
    "        if output_I_std != 0:\n",
    "            output_I = (output_I - output_I_mean) / output_I_std\n",
    "        if output_Q_std != 0:\n",
    "            output_Q = (output_Q - output_Q_mean) / output_Q_std\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        input_tensor = torch.tensor(np.stack([input_I, input_Q], axis = 1), dtype=torch.float32)  # Full input sequence\n",
    "        target_tensor = torch.tensor([output_I[middle_index], output_Q[middle_index]], dtype=torch.float32)  # Middle output\n",
    "\n",
    "        return input_tensor, target_tensor, middle_time\n",
    "\n",
    "# Align data sizes by truncating to the minimum length\n",
    "if len(input_data) != len(output_data):\n",
    "    min_length = min(len(input_data), len(output_data))\n",
    "    input_data = input_data[:min_length]\n",
    "    output_data = output_data[:min_length]\n",
    "else:\n",
    "    print(\"no truncating necessary\")\n",
    "\n",
    "# Replace NaN values with the mean of the column\n",
    "for i in range(1, 3):  # Columns 1 and 2 (I and Q)\n",
    "    if np.isnan(input_data[:, i]).any():\n",
    "        input_mean = np.nanmean(input_data[:, i])\n",
    "        input_data[np.isnan(input_data[:, i]), i] = input_mean\n",
    "    else:\n",
    "        print(\"no NaN values found in input data\")\n",
    "\n",
    "for i in range(1, 3):  # Columns 1 and 2 (I and Q)\n",
    "    if np.isnan(output_data[:, i]).any():\n",
    "        output_mean = np.nanmean(output_data[:, i])\n",
    "        output_data[np.isnan(output_data[:, i]), i] = output_mean\n",
    "    else:\n",
    "        print(\"no NaN values found in output data\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert NumPy arrays to lists for Plotly compatibility\n",
    "time_input_list = input_data[:, 0].tolist()\n",
    "I_input_list = input_data[:, 1].tolist()\n",
    "Q_input_list = input_data[:, 2].tolist()\n",
    "\n",
    "time_output_list = output_data[:, 0].tolist()\n",
    "I_output_list = output_data[:, 1].tolist()\n",
    "Q_output_list = output_data[:, 2].tolist()\n",
    "\n",
    "plot_two_lines(\n",
    "    x1=time_input_list, y1=I_input_list,\n",
    "    x2=time_output_list, y2=I_output_list,\n",
    "    title=\"raw in-phase input and output data \",\n",
    "    x_label=\"time\", y_label=\"amplitude\",\n",
    "    label1=\"input\", label2=\"output\"\n",
    ")\n",
    "\n",
    "plot_two_lines(\n",
    "    x1=time_input_list, y1=Q_input_list,\n",
    "    x2=time_output_list, y2=Q_output_list,\n",
    "    title=\"raw quadrature input and output data \",\n",
    "    x_label=\"time\", y_label=\"amplitude\",\n",
    "    label1=\"input\", label2=\"output\"\n",
    ")\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "# input_data = np.vstack(input_data)\n",
    "# output_data = np.vstack(output_data)\n",
    "\n",
    "data = np.column_stack((\n",
    "    input_data[:, 0],  # Time\n",
    "    input_data[:, 1],  # Input I\n",
    "    input_data[:, 2],  # Input Q\n",
    "    output_data[:, 1], # Output I\n",
    "    output_data[:, 2]  # Output Q\n",
    "))\n",
    "\n",
    "# Define window and step sizes\n",
    "window_size = 256\n",
    "step_size = 1  # Adjust step size to control overlap\n",
    "\n",
    "# Create dataset instance\n",
    "dataset = ModelDataset(data, window_size, step_size)\n",
    "\n",
    "# Split dataset into train, validation, and test\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Define DataLoaders with shuffle only for training\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Verify DataLoader\n",
    "print(f\"Total Training Batches: {len(train_loader)}\")\n",
    "for batch_idx, (X_batch, y_batch, _) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1} - X shape: {X_batch.shape}, y shape: {y_batch.shape}\")\n",
    "    break  # Print only the first batch"
   ],
   "id": "b14cc9b523dbecce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "step3",
   "id": "ff4e2416add9fd48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model 0:",
   "id": "a98b6d8ebc24cc79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the basic FNN model\n",
    "class FiberOpticFNN0(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(FiberOpticFNN0, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),  # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),  # Dropout for regularization\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),  # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ],
   "id": "2f4d79756a0f4371",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model 1",
   "id": "38b4d7d081836869"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the deeper model\n",
    "class FiberOpticFNN1(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(FiberOpticFNN1, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ],
   "id": "4c82329a1bfa2a0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model 2",
   "id": "5e1ccb36c0b13834"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the wider model\n",
    "class FiberOpticFNN2(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(FiberOpticFNN2, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ],
   "id": "51f66fe99fe6384b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model 3",
   "id": "1aa263880219e8e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the dynamic model\n",
    "class FiberOpticFNN3(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(FiberOpticFNN3, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, int(hidden_dim * 0.75)),\n",
    "            nn.BatchNorm1d(int(hidden_dim * 0.75)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(int(hidden_dim * 0.75), int(hidden_dim * 0.5)),\n",
    "            nn.BatchNorm1d(int(hidden_dim * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(int(hidden_dim * 0.5), output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ],
   "id": "8e43a2b96e439c31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model 4",
   "id": "c09232f27e7ec407"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the noise-resilient model\n",
    "class FiberOpticFNN4(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(FiberOpticFNN4, self).__init__()\n",
    "\n",
    "        # Initial feature extraction\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Noise-focused branch (captures small deviations)\n",
    "        self.noise_branch = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # Residual connection for refined outputs\n",
    "        self.residual = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Final layer combining noise and refined features\n",
    "        self.combined = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.feature_extractor(x)\n",
    "\n",
    "        # Process noise-sensitive features\n",
    "        noise_features = self.noise_branch(features)\n",
    "\n",
    "        # Add residual connection\n",
    "        refined_features = features + self.residual(features)\n",
    "\n",
    "        # Combine noise-sensitive and refined features\n",
    "        combined_input = torch.cat((refined_features, noise_features), dim=1)\n",
    "\n",
    "        # Final output\n",
    "        output = self.combined(combined_input)\n",
    "        return output"
   ],
   "id": "b38c095ca09080d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model 5",
   "id": "e171a43322dfa63c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the Residual Connections model\n",
    "class FiberOpticFNN5(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FiberOpticFNN5, self).__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.hidden_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = x + self.hidden_layer(x)  # Residual connection\n",
    "        return self.output_layer(x)"
   ],
   "id": "29edd6858a518c69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "step 4",
   "id": "b202a7747007608b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_weights = None\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch, _ in train_loader:\n",
    "\n",
    "            # Move data to GPU\n",
    "            X_batch = X_batch.to(device).view(X_batch.shape[0], -1)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch, _ in val_loader:\n",
    "\n",
    "                # Move data to GPU\n",
    "                X_batch = X_batch.to(device).view(X_batch.shape[0], -1)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                predictions = model(X_batch)\n",
    "                loss = criterion(predictions, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_losses[-1] < best_val_loss:\n",
    "            best_val_loss = val_losses[-1]\n",
    "            patience_counter = 0\n",
    "            best_weights = {\"model weights\": model.state_dict()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    return train_losses, val_losses, best_weights"
   ],
   "id": "c8dcfba1192f9fd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "step 5",
   "id": "29e05a37ee6030aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial, model_name, model_class):\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    # Define model subdirectory\n",
    "    model_dir = os.path.join(results_dir, '256QAM', model_name, 'saved model')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Hyperparameters to tune\n",
    "    hidden_dim = trial.suggest_int(\"hidden dim\", 256, 640, step=32)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight decay\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    # Model arguments dictionary\n",
    "    model_args = {\n",
    "        \"input_dim\": window_size * 2,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"output_dim\": 2\n",
    "    }\n",
    "\n",
    "    if \"dropout\" in model_class.__init__.__code__.co_varnames:\n",
    "        dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "        model_args[\"dropout\"] = dropout_rate\n",
    "\n",
    "    model = model_class(**model_args)\n",
    "    criterion = nn.MSELoss()  # Define loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)  # Define optimizer\n",
    "\n",
    "    # Train the model\n",
    "    train_losses, val_losses, best_weights = train_model(\n",
    "        model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=100,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    if min(val_losses) < best_val_loss:\n",
    "        best_val_loss = min(val_losses)\n",
    "\n",
    "        #Save model weights\n",
    "        weights_path = os.path.join(model_dir, \"model_weights_windowed.pth\")\n",
    "        torch.save(best_weights, weights_path)\n",
    "\n",
    "        # Save best params\n",
    "        best_params = {\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"lr\": lr,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"val_losses\": val_losses\n",
    "        }\n",
    "        if \"dropout\" in model_args:\n",
    "            best_params[\"dropout\"] = dropout_rate\n",
    "\n",
    "        params_path = os.path.join(model_dir, \"best_params_windowed.json\")\n",
    "        with open(params_path, \"w\") as json_file:\n",
    "            json.dump(best_params, json_file, indent=4)\n",
    "        print(f\"Files saved successfully: {weights_path}, {params_path}\")\n",
    "\n",
    "    return best_val_loss\n",
    "\n"
   ],
   "id": "999efcc5cbe0d58a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Dictionary mapping model names to their respective classes\n",
    "model_info = {\n",
    "    \"Basic\": FiberOpticFNN0,\n",
    "    \"Deeper\": FiberOpticFNN1,\n",
    "    \"Wider\": FiberOpticFNN2,\n",
    "    \"Dynamic\": FiberOpticFNN3,\n",
    "    \"Noise Resilient\": FiberOpticFNN4,\n",
    "     \"Residual\": FiberOpticFNN5\n",
    "}\n",
    "\n",
    "# Run Optuna study for each model\n",
    "for model_name, model_class in model_info.items():\n",
    "    print(f\"ðŸ”„ Running Optuna for {model_name} model...\")\n",
    "\n",
    "    # Create an Optuna study\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "    # Optimize using lambda to pass additional arguments\n",
    "    study.optimize(lambda trial: objective(trial, model_name, model_class), n_trials=15)\n",
    "\n",
    "    print(f\"âœ… Finished optimization for {model_name}\\n\")\n"
   ],
   "id": "61c2f98c42d00aec",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
