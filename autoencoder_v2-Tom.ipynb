{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Charlie AutoEncoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "TyemDLPdJeU4"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Generate random symbols as input\n",
    "def generate_symbols(input_length, M):\n",
    "    return torch.randint(0, M, (input_length,))  # generate (batch_size) random symbols between 0 and M - 1\n",
    "\n",
    "# Create sliding windows from input data\n",
    "def create_windows(data, window_size, step_size):\n",
    "    num_windows = (len(data) - window_size) // step_size + 1\n",
    "    windows = torch.stack([\n",
    "        data[i:i + window_size]  # Extract rows for each window\n",
    "        for i in range(0, num_windows * step_size, step_size)\n",
    "    ])\n",
    "\n",
    "    return windows\n",
    "\n",
    "def plot_two_lines(x1, y1, x2, y2, title, x_label, y_label, label1=\"Line 1\", label2=\"Line 2\"):\n",
    "    \"\"\"\n",
    "    Creates an interactive Plotly plot for two solid lines over the same x-axis.\n",
    "\n",
    "    Parameters:\n",
    "    - x1, y1: Data for the first line\n",
    "    - x2, y2: Data for the second line\n",
    "    - title: Plot title\n",
    "    - x_label: Label for the x-axis\n",
    "    - y_label: Label for the y-axis\n",
    "    - label1: Legend name for the first line (default: \"Line 1\")\n",
    "    - label2: Legend name for the second line (default: \"Line 2\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an interactive figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add first line trace (solid blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x1, y=y1,\n",
    "        mode='lines', name=label1,\n",
    "        line=dict(color='blue', width=2)  # Solid line, blue color\n",
    "    ))\n",
    "\n",
    "    # Add second line trace (solid red)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x2, y=y2,\n",
    "        mode='lines', name=label2,\n",
    "        line=dict(color='red', width=2)  # Solid line, red color\n",
    "    ))\n",
    "\n",
    "    # Configure layout for better visibility\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=x_label,\n",
    "        yaxis_title=y_label,\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"x\",  # Enables hover tool on x-axis\n",
    "    )\n",
    "\n",
    "    # Show the interactive plot\n",
    "    fig.show()\n",
    "\n",
    "def plot_losses(losses):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(losses, label=\"Training Loss\", color=\"blue\", alpha=0.7)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZjAcV_7A52C"
   },
   "source": [
    "# REMEMBER TO IMPORT: model_weights_windowed.pth, best_params_windowed.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdpaC4p2mbm0"
   },
   "source": [
    "# MODIFIED TRAINING (INTEGRATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9pbnCZk1vHpu",
    "outputId": "24872bab-3661-45e7-a7b9-becb045cc929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - Loss: 5.4809\n",
      "Epoch [2/100] - Loss: 5.5839\n",
      "Epoch [3/100] - Loss: 5.5433\n",
      "Epoch [4/100] - Loss: 5.5124\n",
      "Epoch [5/100] - Loss: 5.4989\n",
      "Epoch [6/100] - Loss: 5.5554\n",
      "Epoch [7/100] - Loss: 5.5063\n",
      "Epoch [8/100] - Loss: 5.6948\n",
      "Epoch [9/100] - Loss: 5.5529\n",
      "Epoch [10/100] - Loss: 5.5263\n",
      "Epoch [11/100] - Loss: 5.6062\n",
      "Epoch [12/100] - Loss: 4.8407\n",
      "Epoch [13/100] - Loss: 5.5210\n",
      "Epoch [14/100] - Loss: 5.5216\n",
      "Epoch [15/100] - Loss: 5.6231\n",
      "Epoch [16/100] - Loss: 5.6962\n",
      "Epoch [17/100] - Loss: 5.6439\n",
      "Epoch [18/100] - Loss: 5.6668\n",
      "Epoch [19/100] - Loss: 5.4898\n",
      "Epoch [20/100] - Loss: 5.4459\n",
      "Epoch [21/100] - Loss: 5.5525\n",
      "Epoch [22/100] - Loss: 5.6656\n",
      "Epoch [23/100] - Loss: 5.6467\n",
      "Epoch [24/100] - Loss: 5.5672\n",
      "Epoch [25/100] - Loss: 5.6849\n",
      "Epoch [26/100] - Loss: 5.7101\n",
      "Epoch [27/100] - Loss: 5.6005\n",
      "Epoch [28/100] - Loss: 5.4906\n",
      "Epoch [29/100] - Loss: 5.8069\n",
      "Epoch [30/100] - Loss: 5.5083\n",
      "Epoch [31/100] - Loss: 5.5452\n",
      "Epoch [32/100] - Loss: 5.6660\n",
      "Epoch [33/100] - Loss: 5.5602\n",
      "Epoch [34/100] - Loss: 5.5945\n",
      "Epoch [35/100] - Loss: 5.6004\n",
      "Epoch [36/100] - Loss: 5.7769\n",
      "Epoch [37/100] - Loss: 5.6369\n",
      "Epoch [38/100] - Loss: 5.6085\n",
      "Epoch [39/100] - Loss: 5.5944\n",
      "Epoch [40/100] - Loss: 5.6572\n",
      "Epoch [41/100] - Loss: 4.1282\n",
      "Epoch [42/100] - Loss: 5.6876\n",
      "Epoch [43/100] - Loss: 5.4569\n",
      "Epoch [44/100] - Loss: 5.5899\n",
      "Epoch [45/100] - Loss: 5.8380\n",
      "Epoch [46/100] - Loss: 4.9884\n",
      "Epoch [47/100] - Loss: 5.7825\n",
      "Epoch [48/100] - Loss: 6.0068\n",
      "Epoch [49/100] - Loss: 5.6512\n",
      "Epoch [50/100] - Loss: 5.6955\n",
      "Epoch [51/100] - Loss: 5.5263\n",
      "Epoch [52/100] - Loss: 5.8617\n",
      "Epoch [53/100] - Loss: 5.6855\n",
      "Epoch [54/100] - Loss: 5.7462\n",
      "Epoch [55/100] - Loss: 5.8277\n",
      "Epoch [56/100] - Loss: 5.0959\n",
      "Epoch [57/100] - Loss: 6.1072\n",
      "Epoch [58/100] - Loss: 5.8066\n",
      "Epoch [59/100] - Loss: 4.8596\n",
      "Epoch [60/100] - Loss: 5.2957\n",
      "Epoch [61/100] - Loss: 6.0785\n",
      "Epoch [62/100] - Loss: 5.6745\n",
      "Epoch [63/100] - Loss: 5.6952\n",
      "Epoch [64/100] - Loss: 5.7252\n",
      "Epoch [65/100] - Loss: 5.6979\n",
      "Epoch [66/100] - Loss: 4.1376\n",
      "Epoch [67/100] - Loss: 5.8017\n",
      "Epoch [68/100] - Loss: 6.0744\n",
      "Epoch [69/100] - Loss: 5.9202\n",
      "Epoch [70/100] - Loss: 5.9076\n",
      "Epoch [71/100] - Loss: 4.5016\n",
      "Epoch [72/100] - Loss: 5.9566\n",
      "Epoch [73/100] - Loss: 5.9839\n",
      "Epoch [74/100] - Loss: 5.8729\n",
      "Epoch [75/100] - Loss: 5.8119\n",
      "Epoch [76/100] - Loss: 5.7374\n",
      "Epoch [77/100] - Loss: 5.9612\n",
      "Epoch [78/100] - Loss: 5.8427\n",
      "Epoch [79/100] - Loss: 4.9640\n",
      "Epoch [80/100] - Loss: 5.2240\n",
      "Epoch [81/100] - Loss: 5.9438\n",
      "Epoch [82/100] - Loss: 4.7716\n",
      "Epoch [83/100] - Loss: 6.0354\n",
      "Epoch [84/100] - Loss: 5.6960\n",
      "Epoch [85/100] - Loss: 5.9392\n",
      "Epoch [86/100] - Loss: 5.9431\n",
      "Epoch [87/100] - Loss: 5.2548\n",
      "Epoch [88/100] - Loss: 5.9632\n",
      "Epoch [89/100] - Loss: 4.7997\n",
      "Epoch [90/100] - Loss: 5.9979\n",
      "Epoch [91/100] - Loss: 5.8850\n",
      "Epoch [92/100] - Loss: 5.9958\n",
      "Epoch [93/100] - Loss: 5.9005\n",
      "Epoch [94/100] - Loss: 6.0047\n",
      "Epoch [95/100] - Loss: 5.9468\n",
      "Epoch [96/100] - Loss: 5.9452\n",
      "Epoch [97/100] - Loss: 5.9172\n",
      "Epoch [98/100] - Loss: 5.9532\n",
      "Epoch [99/100] - Loss: 5.4989\n",
      "Epoch [100/100] - Loss: 5.0077\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loader(weights_filepath, params_filepath):\n",
    "    weights = torch.load(weights_filepath, weights_only=True, map_location=torch.device('cpu'))\n",
    "    with open(params_filepath, \"r\") as f:\n",
    "        params = json.load(f)\n",
    "    return weights, params\n",
    "\n",
    "# Load model weights and parameters\n",
    "weights, params = loader(\n",
    "    r\"C:\\Users\\tomha\\Documents\\Capstone D2 - PC\\Constellation\\256QAM and 256 PSK\\Basic\\model_weights.pth\",\n",
    "    r\"C:\\Users\\tomha\\Documents\\Capstone D2 - PC\\Constellation\\256QAM and 256 PSK\\Basic\\best_params.json\"\n",
    ")\n",
    "\n",
    "# Hyperparameters\n",
    "M = 256\n",
    "n = 2\n",
    "window_size = 512\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Define Transmitter\n",
    "class Transmitter(nn.Module):\n",
    "    def __init__(self, M, n):\n",
    "        super(Transmitter, self).__init__()\n",
    "        self.fc1 = nn.Linear(M, 8 * M)\n",
    "        self.fc2 = nn.Linear(8 * M, 8 * M) # try wider model deeper\n",
    "        self.fc3 = nn.Linear(8 * M, n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define Channel\n",
    "# Define the wider model\n",
    "class FiberOpticFNN0(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(FiberOpticFNN0, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),  # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),  # Dropout for regularization\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),  # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class IdentityChannel(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "# Define Receiver\n",
    "class Receiver(nn.Module):\n",
    "    def __init__(self, n, M):\n",
    "        super(Receiver, self).__init__()\n",
    "        self.fc1 = nn.Linear(n, 8 * M)\n",
    "        self.fc2 = nn.Linear(8 * M, 8 * M)  # try wider model -> deeper\n",
    "        self.fc3 = nn.Linear(8 * M, M)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "transmitter = Transmitter(M, n)\n",
    "\n",
    "channel = FiberOpticFNN0(2 * window_size, params[\"hidden_dim\"], n, params[\"dropout\"])\n",
    "channel.load_state_dict(weights[\"model weights\"], strict=False)\n",
    "# channel = IdentityChannel();\n",
    "\n",
    "receiver = Receiver(n, M)\n",
    "\n",
    "for param in transmitter.parameters():\n",
    "    assert param.requires_grad\n",
    "for param in channel.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in receiver.parameters():\n",
    "    assert param.requires_grad\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(transmitter.parameters()) + list(receiver.parameters()), lr=learning_rate)\n",
    "\n",
    "# Training loop with batching\n",
    "transmitter.train()\n",
    "channel.eval()\n",
    "receiver.train()\n",
    "training_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  symbols = torch.randint(0, M, (window_size,))\n",
    "  target_symbol = symbols[window_size // 2]\n",
    "  symbols_one_hot = F.one_hot(symbols, num_classes=M).float()\n",
    "\n",
    "  transmitted = transmitter(symbols_one_hot)\n",
    "\n",
    "  transmitted_flat = transmitted.view(1, -1)\n",
    "  received = channel(transmitted_flat)\n",
    "\n",
    "  decoded = receiver(received)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  loss = criterion(decoded, target_symbol.unsqueeze(0))\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {loss.item():.4f}\")\n",
    "  training_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>AutoEncoder Attempt #2 - no sliding window</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "\n",
    "class TransmitterRecieverModel(nn.Module):\n",
    "    def __init__(self, input_size,hidden_size,channel_size,channel_func,weight_init=1):\n",
    "        super().__init__()\n",
    "        self.transmitter_fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.transmitter_fc2 = nn.Linear(hidden_size, channel_size)\n",
    "\n",
    "        self.reciever_fc1 = nn.Linear(channel_size, hidden_size)\n",
    "        self.reciever_fc2 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        self.channel_function = channel_func\n",
    "\n",
    "        init.uniform_(self.transmitter_fc1.weight,a=-weight_init,b=weight_init)\n",
    "        init.uniform_(self.transmitter_fc2.weight, a=-weight_init,b=weight_init)\n",
    "        init.uniform_(self.reciever_fc1.weight, a=-weight_init,b=weight_init)\n",
    "        init.uniform_(self.reciever_fc2.weight,a=-weight_init,b=weight_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        transmitter_output = F.sigmoid(self.transmitter_fc1(x))\n",
    "        transmitter_output = self.transmitter_fc2(transmitter_output)\n",
    "\n",
    "        channel_output = self.channel_function(transmitter_output)\n",
    "\n",
    "        reciever_output = F.sigmoid(self.reciever_fc1(channel_output))\n",
    "        reciever_output = self.reciever_fc2(reciever_output)\n",
    "\n",
    "        return reciever_output\n",
    "    \n",
    "    def evaluate(self, x):\n",
    "        with torch.no_grad():\n",
    "            output = F.softmax(self.forward(x),dim=-1)\n",
    "            output = [torch.argmax(o).item() for o in output]\n",
    "            return output\n",
    "\n",
    "\n",
    "    def train_model(self,x,y,epochs=10,learning_rate=0.001):\n",
    "        training_loss = []\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(),lr=learning_rate)\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self.forward(x)\n",
    "            loss = criterion(y_pred,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss.append(loss.item())\n",
    "            #print(f\"Epoch {epoch} Loss: {loss.item()}\")\n",
    "        return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomha\\AppData\\Local\\Temp\\ipykernel_16608\\841660291.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = model.evaluate(torch.tensor(input_data_one_hot,dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data: \n",
      "tensor([220, 152,  30,  90,  89,  56, 104, 184, 252,  28,  59,  70, 180, 153,\n",
      "        115, 179, 231, 178, 251, 144, 103,  74,  34,  81, 115,  20, 144, 205,\n",
      "         22, 208,  67, 111,  46, 167,  39, 150, 165, 239,  75, 112,  22, 246,\n",
      "        162,  35, 196, 130, 205, 158,  70, 220, 216,  77,  91, 198,  39, 250,\n",
      "        133,  91, 130, 248,  72,  70, 217,  38, 247, 163, 137, 223,  66, 205,\n",
      "        246, 238, 109,  94, 134,  51, 144,   2, 213, 194,  39,  52,  83,  99,\n",
      "         29, 111,  94, 129,   9, 120,  41, 109, 123, 110,  44,  27, 172, 152,\n",
      "        231, 159,  50, 133, 168,  61, 252, 167, 251,  41, 129,  75, 200, 248,\n",
      "        113,  35,  75,  37, 246, 101,  69, 151, 226, 122, 178,  83, 183,   8,\n",
      "        138,  50,  34, 133,  40, 194, 191, 190,  42,  82,  14, 113,  43,   5,\n",
      "        235,  24, 239, 242, 248, 108,  79, 231, 234, 101, 246,  48,  35, 120,\n",
      "         78, 125, 164,  48, 222, 190, 104, 154, 173,  10,  22, 168,  60,  62,\n",
      "        216, 118, 164,  72, 168, 190,   1, 237, 188, 227, 199, 236, 164, 220,\n",
      "        174,  70, 151,  27,   8,  45,   5, 247,   3, 178, 235, 159, 160, 239,\n",
      "        178,  33, 111, 191,  85, 128,  64, 206, 189, 214,  57, 236,   2,  91,\n",
      "         34,  49,   6,   3, 125, 208, 105, 168, 186, 219,  78, 199,   1,  54,\n",
      "        173,  92,   8, 152, 121, 122,  34, 238, 105, 105, 214,  46,  89,  53,\n",
      "        223, 241, 113, 105,  27, 120, 171, 135,  19, 227, 227, 250, 143, 223,\n",
      "        244,  85, 225, 187])\n",
      "Output Data: \n",
      "[220, 152, 30, 90, 89, 56, 104, 184, 252, 28, 59, 70, 180, 153, 115, 179, 231, 178, 251, 144, 103, 74, 34, 81, 115, 20, 144, 205, 22, 208, 67, 111, 46, 167, 39, 150, 165, 239, 75, 112, 22, 246, 162, 35, 196, 130, 205, 158, 70, 220, 216, 77, 91, 198, 39, 250, 133, 91, 130, 248, 72, 70, 217, 38, 247, 163, 137, 223, 66, 205, 246, 238, 109, 94, 134, 51, 144, 2, 213, 194, 39, 52, 83, 99, 29, 111, 94, 129, 9, 120, 41, 109, 123, 110, 44, 27, 172, 152, 231, 159, 50, 133, 168, 61, 252, 167, 251, 41, 129, 75, 200, 248, 113, 35, 75, 37, 246, 101, 69, 151, 226, 122, 178, 83, 183, 8, 138, 50, 34, 133, 40, 194, 191, 190, 42, 82, 14, 113, 43, 5, 235, 24, 239, 242, 248, 108, 79, 231, 234, 101, 246, 48, 35, 120, 78, 125, 164, 48, 222, 190, 104, 154, 173, 10, 22, 168, 60, 62, 216, 118, 164, 72, 168, 190, 1, 237, 188, 227, 199, 236, 164, 220, 174, 70, 151, 27, 8, 45, 5, 247, 3, 178, 235, 159, 160, 239, 178, 33, 111, 191, 85, 128, 64, 206, 189, 214, 57, 236, 2, 91, 34, 49, 6, 3, 125, 208, 105, 168, 186, 219, 78, 199, 1, 54, 173, 92, 8, 152, 121, 122, 34, 238, 105, 105, 214, 46, 89, 53, 223, 241, 113, 105, 27, 120, 171, 135, 19, 227, 227, 250, 143, 223, 244, 85, 225, 187]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# identity matrix --> transmitter --> identity channel --> reciever --> identity matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_size = 256\n",
    "hidden_size = 128\n",
    "channel_size = 2\n",
    "channel_func = lambda x: x\n",
    "\n",
    "model = TransmitterRecieverModel(input_size,hidden_size,channel_size,channel_func)\n",
    "\n",
    "input_data = torch.randint(0, input_size, (input_size,), dtype=torch.long)\n",
    "\n",
    "input_data_one_hot = torch.tensor(np.eye(input_size)[input_data],dtype=torch.float32)\n",
    "\n",
    "training_loss = model.train_model(input_data_one_hot,input_data, learning_rate=0.1,epochs=1000)\n",
    "\n",
    "output = model.evaluate(torch.tensor(input_data_one_hot,dtype=torch.float32))\n",
    "print(\"Input Data: \")\n",
    "print(input_data)\n",
    "print(\"Output Data: \")\n",
    "print(output)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(training_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>AutoEncoder Attempt #2 - With sliding window & Fiber Channel</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "def loader(weights_filepath, params_filepath):\n",
    "    weights = torch.load(weights_filepath, weights_only=True, map_location=torch.device('cpu'))\n",
    "    with open(params_filepath, \"r\") as f:\n",
    "        params = json.load(f)\n",
    "    return weights, params\n",
    "\n",
    "# Load model weights and parameters\n",
    "weights, params = loader(\n",
    "    r\"C:\\Users\\tomha\\Documents\\Capstone D2 - PC\\Constellation\\256QAM and 256 PSK\\Basic\\model_weights.pth\",\n",
    "    r\"C:\\Users\\tomha\\Documents\\Capstone D2 - PC\\Constellation\\256QAM and 256 PSK\\Basic\\best_params.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Autoencoder that groups input into windows BEFORE encoding.\n",
    "class AutoEncoderV2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, channel_size, channel_func, window_length):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): Dimensionality of one-hot vectors (alphabet size).\n",
    "            hidden_size (int): Hidden layer dimension.\n",
    "            channel_size (int): Dimension of the transmitter output (e.g., 2 for I/Q).\n",
    "            channel_func (callable): The fiber channel function. It expects an input of size (2 * window_length).\n",
    "            window_length (int): Number of symbols per window.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = input_size      # e.g., 4096 (alphabet size)\n",
    "        self.window_length = window_length  # e.g., 1024\n",
    "        self.channel_size = channel_size    # e.g., 2 (I/Q)\n",
    "\n",
    "        # Transmitter: processes one symbol at a time.\n",
    "        self.transmitter_fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.transmitter_fc2 = nn.Linear(hidden_size, channel_size)\n",
    "\n",
    "        self.channel_function = channel_func\n",
    "        \n",
    "        # Receiver: decodes the channel output back to logits over the alphabet.\n",
    "        self.reciever_fc1 = nn.Linear(channel_size, hidden_size)\n",
    "        self.reciever_fc2 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "     \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (total_length, input_size), where total_length is divisible by window_length.\n",
    "        Returns:\n",
    "            A tensor of shape (num_windows, input_size), where each row corresponds to the receiver's\n",
    "            output for that window.\n",
    "        \"\"\"\n",
    "        # Group input into non-overlapping windows of size window_length.\n",
    "        num_windows = x.shape[0] // self.window_length\n",
    "        # New shape: (num_windows, window_length, input_size)\n",
    "        x_windows = x.view(num_windows, self.window_length, self.input_size)\n",
    "        \n",
    "        # Process each symbol in each window through the transmitter.\n",
    "        x_flat = x_windows.view(-1, self.input_size)  # Shape: (num_windows * window_length, input_size)\n",
    "        tx_hidden = torch.sigmoid(self.transmitter_fc1(x_flat))\n",
    "        tx_symbols = self.transmitter_fc2(tx_hidden)     # Shape: (num_windows * window_length, channel_size)\n",
    "        \n",
    "        # Reshape back into windows: (num_windows, window_length, channel_size)\n",
    "        tx_windows = tx_symbols.view(num_windows, self.window_length, self.channel_size)\n",
    "        \n",
    "        # Flatten each window to create a vector of size (window_length * channel_size).\n",
    "        # With window_length=1024 and channel_size=2, this gives a vector of size 2048.\n",
    "        tx_windows_flat = tx_windows.view(num_windows, -1)\n",
    "        \n",
    "        # Pass each flattened window through the fiber channel.\n",
    "        channel_out = self.channel_function(tx_windows_flat)  # Expected shape: (num_windows, channel_size)\n",
    "        \n",
    "        # Decode the channel output using the receiver.\n",
    "        rx_hidden = torch.sigmoid(self.reciever_fc1(channel_out))\n",
    "        rx_output = self.reciever_fc2(rx_hidden)  # Shape: (num_windows, input_size)\n",
    "        return rx_output\n",
    "\n",
    "    def evaluate(self, x):\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(x)\n",
    "            output_soft = F.softmax(output, dim=-1)\n",
    "            preds = torch.argmax(output_soft, dim=-1)\n",
    "            return preds\n",
    "\n",
    "    def train_model(self, x, y, epochs=10, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (total_length, input_size)\n",
    "            y: Tensor of shape (num_windows,) with the target symbol (class index) for each window.\n",
    "        \"\"\"\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        loss_history = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self.forward(x)  # Shape: (num_windows, input_size)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_history.append(loss.item())\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch} Loss: {loss.item()}\")\n",
    "\n",
    "        # Plot the loss over epochs\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(loss_history, label=\"Training Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Loss over Epochs\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Paramaters\n",
    "window_length = 512 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiberOpticFNN0(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout):\n",
    "        super(FiberOpticFNN0, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),  # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),  # Dropout for regularization\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),  # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "# Set up the fiber channel.\n",
    "channel = FiberOpticFNN0(window_length, params[\"hidden_dim\"], 2, params[\"dropout\"])\n",
    "channel.load_state_dict(weights[\"model weights\"], strict=False)\n",
    "channel_func = lambda x: channel.forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the autoencoder\n",
    "\n",
    "#1 - Initialize the AutoEncoder\n",
    "\n",
    "alphabet_size = 4096    # One-hot vector dimension; using 4096 symbols.\n",
    "hidden_size = 10\n",
    "channel_size = 2        # I/Q components.\n",
    "window_length = 1024    # Each window has 1024 symbols.\n",
    "total_length = 4096     # Total number of symbols (4096/1024 = 4 windows).\n",
    "\n",
    "\n",
    "# Instantiate the autoencoder model.\n",
    "model = AutoEncoderV2(\n",
    "    input_size=alphabet_size, \n",
    "    hidden_size=hidden_size, \n",
    "    channel_size=channel_size, \n",
    "    channel_func=channel_func, \n",
    "    window_length=window_length\n",
    ")\n",
    "\n",
    "\n",
    "#2 - The input data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Generate input data.\n",
    "# Here we generate a sequence of 4096 symbols (0, 1, 2, ..., 4095).\n",
    "input_data = np.array(range(total_length))  # Shape: (4096,)\n",
    "# One-hot encode each symbol: shape (4096, 4096)\n",
    "input_data_one_hot = np.eye(alphabet_size)[input_data]\n",
    "\n",
    "# Group the input into non-overlapping windows for target calculation.\n",
    "# Reshape into (num_windows, window_length).\n",
    "input_data_windows = input_data.reshape(-1, window_length)\n",
    "# For each window, choose the middle symbol (index window_length // 2) as the target.\n",
    "target_data = input_data_windows[:, window_length // 2]  # Shape: (num_windows,)\n",
    "\n",
    "# Convert data to PyTorch tensors.\n",
    "input_tensor = torch.tensor(input_data_one_hot, dtype=torch.float32)  # Shape: (4096, 4096)\n",
    "target_tensor = torch.tensor(target_data, dtype=torch.long)           # Shape: (4096 / 1024,)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Train the model and plot loss.\n",
    "loss_history = model.train_model(input_tensor, target_tensor, learning_rate=0.1, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "input data is [   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "   28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "   42   43   44   45   46   47   48   49   50   51   52   53   54   55\n",
      "   56   57   58   59   60   61   62   63   64   65   66   67   68   69\n",
      "   70   71   72   73   74   75   76   77   78   79   80   81   82   83\n",
      "   84   85   86   87   88   89   90   91   92   93   94   95   96   97\n",
      "   98   99  100  101  102  103  104  105  106  107  108  109  110  111\n",
      "  112  113  114  115  116  117  118  119  120  121  122  123  124  125\n",
      "  126  127  128  129  130  131  132  133  134  135  136  137  138  139\n",
      "  140  141  142  143  144  145  146  147  148  149  150  151  152  153\n",
      "  154  155  156  157  158  159  160  161  162  163  164  165  166  167\n",
      "  168  169  170  171  172  173  174  175  176  177  178  179  180  181\n",
      "  182  183  184  185  186  187  188  189  190  191  192  193  194  195\n",
      "  196  197  198  199  200  201  202  203  204  205  206  207  208  209\n",
      "  210  211  212  213  214  215  216  217  218  219  220  221  222  223\n",
      "  224  225  226  227  228  229  230  231  232  233  234  235  236  237\n",
      "  238  239  240  241  242  243  244  245  246  247  248  249  250  251\n",
      "  252  253  254  255  256  257  258  259  260  261  262  263  264  265\n",
      "  266  267  268  269  270  271  272  273  274  275  276  277  278  279\n",
      "  280  281  282  283  284  285  286  287  288  289  290  291  292  293\n",
      "  294  295  296  297  298  299  300  301  302  303  304  305  306  307\n",
      "  308  309  310  311  312  313  314  315  316  317  318  319  320  321\n",
      "  322  323  324  325  326  327  328  329  330  331  332  333  334  335\n",
      "  336  337  338  339  340  341  342  343  344  345  346  347  348  349\n",
      "  350  351  352  353  354  355  356  357  358  359  360  361  362  363\n",
      "  364  365  366  367  368  369  370  371  372  373  374  375  376  377\n",
      "  378  379  380  381  382  383  384  385  386  387  388  389  390  391\n",
      "  392  393  394  395  396  397  398  399  400  401  402  403  404  405\n",
      "  406  407  408  409  410  411  412  413  414  415  416  417  418  419\n",
      "  420  421  422  423  424  425  426  427  428  429  430  431  432  433\n",
      "  434  435  436  437  438  439  440  441  442  443  444  445  446  447\n",
      "  448  449  450  451  452  453  454  455  456  457  458  459  460  461\n",
      "  462  463  464  465  466  467  468  469  470  471  472  473  474  475\n",
      "  476  477  478  479  480  481  482  483  484  485  486  487  488  489\n",
      "  490  491  492  493  494  495  496  497  498  499  500  501  502  503\n",
      "  504  505  506  507  508  509  510  511  512  513  514  515  516  517\n",
      "  518  519  520  521  522  523  524  525  526  527  528  529  530  531\n",
      "  532  533  534  535  536  537  538  539  540  541  542  543  544  545\n",
      "  546  547  548  549  550  551  552  553  554  555  556  557  558  559\n",
      "  560  561  562  563  564  565  566  567  568  569  570  571  572  573\n",
      "  574  575  576  577  578  579  580  581  582  583  584  585  586  587\n",
      "  588  589  590  591  592  593  594  595  596  597  598  599  600  601\n",
      "  602  603  604  605  606  607  608  609  610  611  612  613  614  615\n",
      "  616  617  618  619  620  621  622  623  624  625  626  627  628  629\n",
      "  630  631  632  633  634  635  636  637  638  639  640  641  642  643\n",
      "  644  645  646  647  648  649  650  651  652  653  654  655  656  657\n",
      "  658  659  660  661  662  663  664  665  666  667  668  669  670  671\n",
      "  672  673  674  675  676  677  678  679  680  681  682  683  684  685\n",
      "  686  687  688  689  690  691  692  693  694  695  696  697  698  699\n",
      "  700  701  702  703  704  705  706  707  708  709  710  711  712  713\n",
      "  714  715  716  717  718  719  720  721  722  723  724  725  726  727\n",
      "  728  729  730  731  732  733  734  735  736  737  738  739  740  741\n",
      "  742  743  744  745  746  747  748  749  750  751  752  753  754  755\n",
      "  756  757  758  759  760  761  762  763  764  765  766  767  768  769\n",
      "  770  771  772  773  774  775  776  777  778  779  780  781  782  783\n",
      "  784  785  786  787  788  789  790  791  792  793  794  795  796  797\n",
      "  798  799  800  801  802  803  804  805  806  807  808  809  810  811\n",
      "  812  813  814  815  816  817  818  819  820  821  822  823  824  825\n",
      "  826  827  828  829  830  831  832  833  834  835  836  837  838  839\n",
      "  840  841  842  843  844  845  846  847  848  849  850  851  852  853\n",
      "  854  855  856  857  858  859  860  861  862  863  864  865  866  867\n",
      "  868  869  870  871  872  873  874  875  876  877  878  879  880  881\n",
      "  882  883  884  885  886  887  888  889  890  891  892  893  894  895\n",
      "  896  897  898  899  900  901  902  903  904  905  906  907  908  909\n",
      "  910  911  912  913  914  915  916  917  918  919  920  921  922  923\n",
      "  924  925  926  927  928  929  930  931  932  933  934  935  936  937\n",
      "  938  939  940  941  942  943  944  945  946  947  948  949  950  951\n",
      "  952  953  954  955  956  957  958  959  960  961  962  963  964  965\n",
      "  966  967  968  969  970  971  972  973  974  975  976  977  978  979\n",
      "  980  981  982  983  984  985  986  987  988  989  990  991  992  993\n",
      "  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007\n",
      " 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021\n",
      " 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035\n",
      " 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049\n",
      " 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063\n",
      " 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077\n",
      " 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091\n",
      " 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105\n",
      " 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119\n",
      " 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133\n",
      " 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147\n",
      " 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161\n",
      " 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175\n",
      " 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189\n",
      " 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203\n",
      " 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217\n",
      " 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231\n",
      " 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245\n",
      " 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259\n",
      " 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273\n",
      " 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287\n",
      " 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301\n",
      " 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315\n",
      " 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329\n",
      " 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343\n",
      " 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357\n",
      " 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371\n",
      " 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385\n",
      " 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399\n",
      " 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413\n",
      " 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427\n",
      " 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441\n",
      " 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455\n",
      " 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469\n",
      " 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483\n",
      " 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497\n",
      " 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511\n",
      " 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525\n",
      " 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539\n",
      " 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553\n",
      " 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567\n",
      " 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581\n",
      " 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595\n",
      " 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609\n",
      " 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623\n",
      " 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637\n",
      " 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651\n",
      " 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665\n",
      " 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679\n",
      " 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693\n",
      " 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707\n",
      " 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721\n",
      " 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735\n",
      " 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749\n",
      " 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763\n",
      " 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777\n",
      " 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791\n",
      " 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805\n",
      " 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819\n",
      " 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833\n",
      " 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847\n",
      " 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861\n",
      " 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875\n",
      " 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889\n",
      " 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903\n",
      " 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917\n",
      " 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931\n",
      " 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945\n",
      " 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959\n",
      " 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973\n",
      " 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987\n",
      " 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001\n",
      " 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015\n",
      " 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029\n",
      " 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043\n",
      " 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057\n",
      " 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071\n",
      " 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085\n",
      " 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099\n",
      " 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113\n",
      " 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127\n",
      " 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141\n",
      " 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155\n",
      " 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169\n",
      " 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183\n",
      " 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197\n",
      " 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211\n",
      " 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225\n",
      " 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239\n",
      " 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253\n",
      " 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267\n",
      " 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281\n",
      " 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295\n",
      " 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309\n",
      " 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323\n",
      " 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337\n",
      " 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351\n",
      " 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365\n",
      " 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379\n",
      " 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393\n",
      " 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407\n",
      " 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421\n",
      " 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435\n",
      " 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449\n",
      " 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463\n",
      " 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477\n",
      " 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491\n",
      " 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505\n",
      " 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519\n",
      " 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533\n",
      " 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547\n",
      " 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561\n",
      " 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575\n",
      " 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589\n",
      " 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601 2602 2603\n",
      " 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617\n",
      " 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631\n",
      " 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 2645\n",
      " 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657 2658 2659\n",
      " 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673\n",
      " 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687\n",
      " 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701\n",
      " 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715\n",
      " 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729\n",
      " 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743\n",
      " 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757\n",
      " 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771\n",
      " 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785\n",
      " 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797 2798 2799\n",
      " 2800 2801 2802 2803 2804 2805 2806 2807 2808 2809 2810 2811 2812 2813\n",
      " 2814 2815 2816 2817 2818 2819 2820 2821 2822 2823 2824 2825 2826 2827\n",
      " 2828 2829 2830 2831 2832 2833 2834 2835 2836 2837 2838 2839 2840 2841\n",
      " 2842 2843 2844 2845 2846 2847 2848 2849 2850 2851 2852 2853 2854 2855\n",
      " 2856 2857 2858 2859 2860 2861 2862 2863 2864 2865 2866 2867 2868 2869\n",
      " 2870 2871 2872 2873 2874 2875 2876 2877 2878 2879 2880 2881 2882 2883\n",
      " 2884 2885 2886 2887 2888 2889 2890 2891 2892 2893 2894 2895 2896 2897\n",
      " 2898 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909 2910 2911\n",
      " 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923 2924 2925\n",
      " 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937 2938 2939\n",
      " 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951 2952 2953\n",
      " 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965 2966 2967\n",
      " 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979 2980 2981\n",
      " 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993 2994 2995\n",
      " 2996 2997 2998 2999 3000 3001 3002 3003 3004 3005 3006 3007 3008 3009\n",
      " 3010 3011 3012 3013 3014 3015 3016 3017 3018 3019 3020 3021 3022 3023\n",
      " 3024 3025 3026 3027 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037\n",
      " 3038 3039 3040 3041 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051\n",
      " 3052 3053 3054 3055 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065\n",
      " 3066 3067 3068 3069 3070 3071 3072 3073 3074 3075 3076 3077 3078 3079\n",
      " 3080 3081 3082 3083 3084 3085 3086 3087 3088 3089 3090 3091 3092 3093\n",
      " 3094 3095 3096 3097 3098 3099 3100 3101 3102 3103 3104 3105 3106 3107\n",
      " 3108 3109 3110 3111 3112 3113 3114 3115 3116 3117 3118 3119 3120 3121\n",
      " 3122 3123 3124 3125 3126 3127 3128 3129 3130 3131 3132 3133 3134 3135\n",
      " 3136 3137 3138 3139 3140 3141 3142 3143 3144 3145 3146 3147 3148 3149\n",
      " 3150 3151 3152 3153 3154 3155 3156 3157 3158 3159 3160 3161 3162 3163\n",
      " 3164 3165 3166 3167 3168 3169 3170 3171 3172 3173 3174 3175 3176 3177\n",
      " 3178 3179 3180 3181 3182 3183 3184 3185 3186 3187 3188 3189 3190 3191\n",
      " 3192 3193 3194 3195 3196 3197 3198 3199 3200 3201 3202 3203 3204 3205\n",
      " 3206 3207 3208 3209 3210 3211 3212 3213 3214 3215 3216 3217 3218 3219\n",
      " 3220 3221 3222 3223 3224 3225 3226 3227 3228 3229 3230 3231 3232 3233\n",
      " 3234 3235 3236 3237 3238 3239 3240 3241 3242 3243 3244 3245 3246 3247\n",
      " 3248 3249 3250 3251 3252 3253 3254 3255 3256 3257 3258 3259 3260 3261\n",
      " 3262 3263 3264 3265 3266 3267 3268 3269 3270 3271 3272 3273 3274 3275\n",
      " 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289\n",
      " 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303\n",
      " 3304 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317\n",
      " 3318 3319 3320 3321 3322 3323 3324 3325 3326 3327 3328 3329 3330 3331\n",
      " 3332 3333 3334 3335 3336 3337 3338 3339 3340 3341 3342 3343 3344 3345\n",
      " 3346 3347 3348 3349 3350 3351 3352 3353 3354 3355 3356 3357 3358 3359\n",
      " 3360 3361 3362 3363 3364 3365 3366 3367 3368 3369 3370 3371 3372 3373\n",
      " 3374 3375 3376 3377 3378 3379 3380 3381 3382 3383 3384 3385 3386 3387\n",
      " 3388 3389 3390 3391 3392 3393 3394 3395 3396 3397 3398 3399 3400 3401\n",
      " 3402 3403 3404 3405 3406 3407 3408 3409 3410 3411 3412 3413 3414 3415\n",
      " 3416 3417 3418 3419 3420 3421 3422 3423 3424 3425 3426 3427 3428 3429\n",
      " 3430 3431 3432 3433 3434 3435 3436 3437 3438 3439 3440 3441 3442 3443\n",
      " 3444 3445 3446 3447 3448 3449 3450 3451 3452 3453 3454 3455 3456 3457\n",
      " 3458 3459 3460 3461 3462 3463 3464 3465 3466 3467 3468 3469 3470 3471\n",
      " 3472 3473 3474 3475 3476 3477 3478 3479 3480 3481 3482 3483 3484 3485\n",
      " 3486 3487 3488 3489 3490 3491 3492 3493 3494 3495 3496 3497 3498 3499\n",
      " 3500 3501 3502 3503 3504 3505 3506 3507 3508 3509 3510 3511 3512 3513\n",
      " 3514 3515 3516 3517 3518 3519 3520 3521 3522 3523 3524 3525 3526 3527\n",
      " 3528 3529 3530 3531 3532 3533 3534 3535 3536 3537 3538 3539 3540 3541\n",
      " 3542 3543 3544 3545 3546 3547 3548 3549 3550 3551 3552 3553 3554 3555\n",
      " 3556 3557 3558 3559 3560 3561 3562 3563 3564 3565 3566 3567 3568 3569\n",
      " 3570 3571 3572 3573 3574 3575 3576 3577 3578 3579 3580 3581 3582 3583\n",
      " 3584 3585 3586 3587 3588 3589 3590 3591 3592 3593 3594 3595 3596 3597\n",
      " 3598 3599 3600 3601 3602 3603 3604 3605 3606 3607 3608 3609 3610 3611\n",
      " 3612 3613 3614 3615 3616 3617 3618 3619 3620 3621 3622 3623 3624 3625\n",
      " 3626 3627 3628 3629 3630 3631 3632 3633 3634 3635 3636 3637 3638 3639\n",
      " 3640 3641 3642 3643 3644 3645 3646 3647 3648 3649 3650 3651 3652 3653\n",
      " 3654 3655 3656 3657 3658 3659 3660 3661 3662 3663 3664 3665 3666 3667\n",
      " 3668 3669 3670 3671 3672 3673 3674 3675 3676 3677 3678 3679 3680 3681\n",
      " 3682 3683 3684 3685 3686 3687 3688 3689 3690 3691 3692 3693 3694 3695\n",
      " 3696 3697 3698 3699 3700 3701 3702 3703 3704 3705 3706 3707 3708 3709\n",
      " 3710 3711 3712 3713 3714 3715 3716 3717 3718 3719 3720 3721 3722 3723\n",
      " 3724 3725 3726 3727 3728 3729 3730 3731 3732 3733 3734 3735 3736 3737\n",
      " 3738 3739 3740 3741 3742 3743 3744 3745 3746 3747 3748 3749 3750 3751\n",
      " 3752 3753 3754 3755 3756 3757 3758 3759 3760 3761 3762 3763 3764 3765\n",
      " 3766 3767 3768 3769 3770 3771 3772 3773 3774 3775 3776 3777 3778 3779\n",
      " 3780 3781 3782 3783 3784 3785 3786 3787 3788 3789 3790 3791 3792 3793\n",
      " 3794 3795 3796 3797 3798 3799 3800 3801 3802 3803 3804 3805 3806 3807\n",
      " 3808 3809 3810 3811 3812 3813 3814 3815 3816 3817 3818 3819 3820 3821\n",
      " 3822 3823 3824 3825 3826 3827 3828 3829 3830 3831 3832 3833 3834 3835\n",
      " 3836 3837 3838 3839 3840 3841 3842 3843 3844 3845 3846 3847 3848 3849\n",
      " 3850 3851 3852 3853 3854 3855 3856 3857 3858 3859 3860 3861 3862 3863\n",
      " 3864 3865 3866 3867 3868 3869 3870 3871 3872 3873 3874 3875 3876 3877\n",
      " 3878 3879 3880 3881 3882 3883 3884 3885 3886 3887 3888 3889 3890 3891\n",
      " 3892 3893 3894 3895 3896 3897 3898 3899 3900 3901 3902 3903 3904 3905\n",
      " 3906 3907 3908 3909 3910 3911 3912 3913 3914 3915 3916 3917 3918 3919\n",
      " 3920 3921 3922 3923 3924 3925 3926 3927 3928 3929 3930 3931 3932 3933\n",
      " 3934 3935 3936 3937 3938 3939 3940 3941 3942 3943 3944 3945 3946 3947\n",
      " 3948 3949 3950 3951 3952 3953 3954 3955 3956 3957 3958 3959 3960 3961\n",
      " 3962 3963 3964 3965 3966 3967 3968 3969 3970 3971 3972 3973 3974 3975\n",
      " 3976 3977 3978 3979 3980 3981 3982 3983 3984 3985 3986 3987 3988 3989\n",
      " 3990 3991 3992 3993 3994 3995 3996 3997 3998 3999 4000 4001 4002 4003\n",
      " 4004 4005 4006 4007 4008 4009 4010 4011 4012 4013 4014 4015 4016 4017\n",
      " 4018 4019 4020 4021 4022 4023 4024 4025 4026 4027 4028 4029 4030 4031\n",
      " 4032 4033 4034 4035 4036 4037 4038 4039 4040 4041 4042 4043 4044 4045\n",
      " 4046 4047 4048 4049 4050 4051 4052 4053 4054 4055 4056 4057 4058 4059\n",
      " 4060 4061 4062 4063 4064 4065 4066 4067 4068 4069 4070 4071 4072 4073\n",
      " 4074 4075 4076 4077 4078 4079 4080 4081 4082 4083 4084 4085 4086 4087\n",
      " 4088 4089 4090 4091 4092 4093 4094 4095]\n",
      "target tensor is tensor([ 256,  768, 1280, 1792, 2304, 2816, 3328, 3840])\n",
      "Target Symbols (middle of each window):\n",
      "[ 256  768 1280 1792 2304 2816 3328 3840]\n",
      "Output Predictions:\n",
      "[ 256  768 1280 1792 2304 2816 3328 3840]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Evaluate the model.\n",
    "print(\"Evaluating the model...\")\n",
    "print(f\"input data is {input_data}\")\n",
    "print(f\"target tensor is {target_tensor}\")\n",
    "\n",
    "output = model.evaluate(input_tensor)\n",
    "print(\"Target Symbols (middle of each window):\")\n",
    "print(target_tensor.cpu().numpy())\n",
    "print(\"Output Predictions:\")\n",
    "print(output.cpu().numpy())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "history_visible": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
